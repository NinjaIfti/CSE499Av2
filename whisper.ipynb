{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xV6Lx_KJZn7",
        "outputId": "6738fe93-de93-4d72-e943-4622afa89e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "âœ… All packages installed!\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install all required packages\n",
        "!pip install openai-whisper fastapi uvicorn python-multipart nest-asyncio pyngrok --quiet\n",
        "!apt-get install -y ffmpeg --quiet\n",
        "print(\"âœ… All packages installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import all libraries\n",
        "import whisper\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, File, UploadFile, Form\n",
        "from fastapi.responses import JSONResponse\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "print(\"âœ… Libraries imported!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtOXOw5AJxYy",
        "outputId": "dffde571-38ec-4c9c-c203-fd49f40f6116"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Libraries imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load the Whisper model (run this once â€” takes a minute)\n",
        "# Options: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
        "# For laptop testing: \"base\" or \"small\" is recommended (fast + decent accuracy)\n",
        "# For best accuracy: \"medium\" or \"large\" (slower)\n",
        "\n",
        "MODEL_SIZE = \"base\"  # Change this if needed\n",
        "\n",
        "print(f\"â³ Loading Whisper model: '{MODEL_SIZE}'...\")\n",
        "model = whisper.load_model(MODEL_SIZE)\n",
        "print(f\"âœ… Whisper model '{MODEL_SIZE}' loaded and ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgrV8CWrJ5ZE",
        "outputId": "7cd800f3-da8c-4dee-acf6-f3d157a315da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Loading Whisper model: 'base'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:01<00:00, 102MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Whisper model 'base' loaded and ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Define the FastAPI app with /transcribe endpoint\n",
        "\n",
        "app = FastAPI(title=\"Whisper Transcription Service\")\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"status\": \"Whisper service is running!\", \"model\": MODEL_SIZE}\n",
        "\n",
        "@app.post(\"/transcribe\")\n",
        "async def transcribe_video(\n",
        "    video: UploadFile = File(...),\n",
        "    job_id: str = Form(...)\n",
        "):\n",
        "    video_path = f\"/tmp/{job_id}_video.mp4\"\n",
        "    audio_path = f\"/tmp/{job_id}_audio.wav\"\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nğŸ“¥ Received job_id: {job_id} | File: {video.filename}\")\n",
        "\n",
        "        # Step 1: Save uploaded video to disk\n",
        "        with open(video_path, \"wb\") as f:\n",
        "            content = await video.read()\n",
        "            f.write(content)\n",
        "        print(f\"âœ… Video saved: {video_path}\")\n",
        "\n",
        "        # Step 2: Extract audio using ffmpeg (mono, 16kHz WAV â€” ideal for Whisper)\n",
        "        ffmpeg_cmd = [\n",
        "            \"ffmpeg\", \"-y\",           # -y = overwrite output if exists\n",
        "            \"-i\", video_path,\n",
        "            \"-vn\",                    # no video\n",
        "            \"-acodec\", \"pcm_s16le\",   # 16-bit PCM\n",
        "            \"-ar\", \"16000\",           # 16kHz sample rate\n",
        "            \"-ac\", \"1\",               # mono channel\n",
        "            audio_path\n",
        "        ]\n",
        "        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode != 0:\n",
        "            raise Exception(f\"ffmpeg error: {result.stderr}\")\n",
        "        print(f\"âœ… Audio extracted: {audio_path}\")\n",
        "\n",
        "        # Step 3: Run Whisper transcription\n",
        "        print(\"â³ Transcribing... (this may take a while for long videos)\")\n",
        "        transcription = model.transcribe(audio_path, verbose=False)\n",
        "        print(\"âœ… Transcription complete!\")\n",
        "\n",
        "        # Step 4: Format response to match Person 4's expected structure\n",
        "        duration = transcription[\"segments\"][-1][\"end\"] if transcription[\"segments\"] else 0.0\n",
        "\n",
        "        formatted_segments = [\n",
        "            {\n",
        "                \"id\": seg[\"id\"],\n",
        "                \"start\": round(seg[\"start\"], 2),\n",
        "                \"end\": round(seg[\"end\"], 2),\n",
        "                \"text\": seg[\"text\"].strip(),\n",
        "                \"confidence\": round(1.0 - seg.get(\"no_speech_prob\", 0.0), 2)\n",
        "            }\n",
        "            for seg in transcription[\"segments\"]\n",
        "        ]\n",
        "\n",
        "        response = {\n",
        "            \"text\": transcription[\"text\"].strip(),\n",
        "            \"segments\": formatted_segments,\n",
        "            \"language\": transcription[\"language\"],\n",
        "            \"duration\": round(duration, 2)\n",
        "        }\n",
        "\n",
        "        print(f\"ğŸ“Š Language: {response['language']} | Duration: {response['duration']}s | Segments: {len(formatted_segments)}\")\n",
        "        return JSONResponse(content=response, status_code=200)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {str(e)}\")\n",
        "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
        "\n",
        "    finally:\n",
        "        # Step 5: Cleanup temp files\n",
        "        for path in [video_path, audio_path]:\n",
        "            if os.path.exists(path):\n",
        "                os.remove(path)\n",
        "                print(f\"ğŸ§¹ Cleaned up: {path}\")\n",
        "\n",
        "print(\"âœ… FastAPI app defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfrP0wKWKA3k",
        "outputId": "2a128a51-6df7-419e-ad49-de5331266e3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FastAPI app defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Set up ngrok and expose the service publicly\n",
        "# Get your free auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"39vUgthPfzH3NGuzDlrPeGgCZ1R_4BTj1TFMMqAEHG3xENwaH\"  # â† Paste your token here\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Kill any existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start tunnel on port 8000\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"=\" * 50)\n",
        "print(f\"ğŸŒ Whisper Service PUBLIC URL:\")\n",
        "print(f\"   {public_url}\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nğŸ“‹ Tell Person 4 to set in .env:\")\n",
        "print(f'   WHISPER_SERVICE_URL={public_url}')\n",
        "print(f\"\\nğŸ“‹ Transcribe endpoint:\")\n",
        "print(f'   POST {public_url}/transcribe')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYg1oqAjKN8y",
        "outputId": "d7019ddf-2889-4098-a98b-b1a565a2e4fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "ğŸŒ Whisper Service PUBLIC URL:\n",
            "   NgrokTunnel: \"https://semioratorical-imputrescible-kristel.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            "==================================================\n",
            "\n",
            "ğŸ“‹ Tell Person 4 to set in .env:\n",
            "   WHISPER_SERVICE_URL=NgrokTunnel: \"https://semioratorical-imputrescible-kristel.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            "\n",
            "ğŸ“‹ Transcribe endpoint:\n",
            "   POST NgrokTunnel: \"https://semioratorical-imputrescible-kristel.ngrok-free.dev\" -> \"http://localhost:8000\"/transcribe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 : Run uvicorn in a background thread (Colab-compatible)\n",
        "import asyncio\n",
        "import threading\n",
        "\n",
        "config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "server = uvicorn.Server(config)\n",
        "\n",
        "# Run server in a separate thread so Colab's event loop doesn't conflict\n",
        "thread = threading.Thread(target=server.run, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Wait a moment for server to start\n",
        "time.sleep(2)\n",
        "print(\"ğŸš€ Whisper server is running on port 8000!\")\n",
        "print(\"âœ… Service is ready to accept requests!\")\n",
        "print(\"âš ï¸  Keep this cell's session alive (don't restart runtime)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB7ckHL1Myt5",
        "outputId": "8ed2ec6c-040a-4b01-b4e9-e07cbf9d5196"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [325]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Whisper server is running on port 8000!\n",
            "âœ… Service is ready to accept requests!\n",
            "âš ï¸  Keep this cell's session alive (don't restart runtime)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Test your service â€” run this from your laptop or another Colab cell\n",
        "# Replace the URL with your actual ngrok URL from Cell 5\n",
        "\n",
        "import requests\n",
        "\n",
        "WHISPER_URL = \"https://semioratorical-imputrescible-kristel.ngrok-free.dev\"  # â† Paste your ngrok URL\n",
        "\n",
        "# Test 1: Health check\n",
        "print(\"ğŸ” Testing health check...\")\n",
        "response = requests.get(f\"{WHISPER_URL}/\")\n",
        "print(f\"Status: {response.status_code}\")\n",
        "print(f\"Response: {response.json()}\")\n",
        "\n",
        "# Test 2: Transcription (replace with your video file path)\n",
        "print(\"\\nğŸ¥ Testing transcription...\")\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/Colab Notebooks/Creative Writing for Kids  7 Tips - Mr Tim's Classroom (1080p, h264) (1).mp4\"  # â† Path to a test video on your laptop\n",
        "\n",
        "with open(VIDEO_PATH, \"rb\") as f:\n",
        "    files = {\"video\": (os.path.basename(VIDEO_PATH), f, \"video/mp4\")}\n",
        "    data = {\"job_id\": \"test_001\"}\n",
        "    response = requests.post(\n",
        "        f\"{WHISPER_URL}/transcribe\",\n",
        "        files=files,\n",
        "        data=data,\n",
        "        timeout=300  # 5 minute timeout\n",
        "    )\n",
        "\n",
        "print(f\"Status: {response.status_code}\")\n",
        "result = response.json()\n",
        "\n",
        "if \"error\" in result:\n",
        "    print(f\"âŒ Error: {result['error']}\")\n",
        "else:\n",
        "    print(f\"âœ… Language: {result['language']}\")\n",
        "    print(f\"âœ… Duration: {result['duration']}s\")\n",
        "    print(f\"âœ… Segments: {len(result['segments'])}\")\n",
        "    print(f\"\\nğŸ“ First 3 segments:\")\n",
        "    for seg in result[\"segments\"][:3]:\n",
        "        print(f\"  [{seg['start']}s â†’ {seg['end']}s] {seg['text']}\")\n",
        "    print(f\"\\nğŸ“ Full transcript preview:\")\n",
        "    print(result[\"text\"][:500] + \"...\" if len(result[\"text\"]) > 500 else result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sev4xchvM5Ag",
        "outputId": "f0b5d812-95ed-4a79-bc62-bfdf451d94f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Testing health check...\n",
            "INFO:     136.117.128.91:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "Status: 200\n",
            "Response: {'status': 'Whisper service is running!', 'model': 'base'}\n",
            "\n",
            "ğŸ¥ Testing transcription...\n",
            "\n",
            "ğŸ“¥ Received job_id: test_001 | File: Creative Writing for Kids  7 Tips - Mr Tim's Classroom (1080p, h264) (1).mp4\n",
            "âœ… Video saved: /tmp/test_001_video.mp4\n",
            "âœ… Audio extracted: /tmp/test_001_audio.wav\n",
            "â³ Transcribing... (this may take a while for long videos)\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75933/75933 [00:26<00:00, 2880.69frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Transcription complete!\n",
            "ğŸ“Š Language: en | Duration: 753.0s | Segments: 153\n",
            "ğŸ§¹ Cleaned up: /tmp/test_001_video.mp4\n",
            "ğŸ§¹ Cleaned up: /tmp/test_001_audio.wav\n",
            "INFO:     136.117.128.91:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "Status: 200\n",
            "âœ… Language: en\n",
            "âœ… Duration: 753.0s\n",
            "âœ… Segments: 153\n",
            "\n",
            "ğŸ“ First 3 segments:\n",
            "  [0.0s â†’ 28.48s] A\n",
            "  [30.0s â†’ 37.0s] Hi kids welcome back to Mr. Tim's classroom. I know it's been a very challenging time for you.\n",
            "  [37.0s â†’ 44.0s] No doubt you've been in front of screens a lot. I just hope that your eyes aren't turning square.\n",
            "\n",
            "ğŸ“ Full transcript preview:\n",
            "A Hi kids welcome back to Mr. Tim's classroom. I know it's been a very challenging time for you. No doubt you've been in front of screens a lot. I just hope that your eyes aren't turning square. I just thought today I might share a little video on creative writing. So I want to give you seven tips to really improve your creative writing skills. Shall we do it together? Alright kids my first tip is start with excitement. I'm sure you guys know of the seven steps to writing and the seasonings star...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}